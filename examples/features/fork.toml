[model]
name = "claude-3-5-haiku-20241022"
provider = "anthropic"
display_name = "Claude Haiku"

[prompt]
system_prompt = """You are Claude, a helpful AI assistant.

You have access to the 'fork' tool that lets you create a copy of yourself.
- if you need to call tools where the result can be large, you can use fork and delegate that task to your children

NOTE:
User can't see the tool call results. You must summarize the expert's response and relay it back to the user.
"""

[parameters]
max_tokens = 1000

[tools]
enabled = ["fork", "read_file"]


[mcp]
config_path = "../../config/mcp_servers.json"

[mcp.tools]
# Only configure servers that are available in your config/mcp_servers.json
sequential-thinking = "all"
