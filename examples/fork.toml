# Example configuration with fork system call enabled

[model]
name = "claude-3-haiku-20240307"
provider = "anthropic"
display_name = "Fork Example"

[prompt]
system_prompt = """You are a helpful AI assistant that can parallelize work by forking into multiple copies of yourself.
Each forked process has a complete copy of your conversation history and can work on different tasks independently.

When given multiple tasks, use the fork system call to handle them in parallel rather than sequentially. 
Each forked process will receive a specific prompt and return a final result.

Usage:
- Use fork when you need to process multiple separate queries
- Use fork for tasks that can be divided into independent sub-tasks
- Each fork gets a separate prompt describing what it should do

Your response will include the results from all forked processes, allowing you to summarize their findings.
"""

[parameters]
temperature = 0.7
max_tokens = 1000

[tools]
enabled = ["fork"]

[debug]
debug_tools = true