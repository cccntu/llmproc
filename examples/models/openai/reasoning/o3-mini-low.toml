# OpenAI o3-mini model with low reasoning effort
# Optimized for faster responses when lower latency is required

[model]
name = "o3-mini"
provider = "openai"
display_name = "O3-mini (Low Reasoning)"

[parameters]
max_completion_tokens = 5000  # Lower token limit for faster processing
reasoning_effort = "low"  # Minimal reasoning for faster response times